{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627e9065",
   "metadata": {},
   "source": [
    "**1. Write a program which will find all numbers which are divisible by 7 but are not a multiple of 5 between 2000 and 3200 (both included) The numbers obtained should be printed in a comma separated sequence on a single line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1bb503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002,2009,2016,2023,2037,2044,2051,2058,2072,2079,2086,2093,2107,2114,2121,2128,2142,2149,2156,2163,2177,2184,2191,2198,2212,2219,2226,2233,2247,2254,2261,2268,2282,2289,2296,2303,2317,2324,2331,2338,2352,2359,2366,2373,2387,2394,2401,2408,2422,2429,2436,2443,2457,2464,2471,2478,2492,2499,2506,2513,2527,2534,2541,2548,2562,2569,2576,2583,2597,2604,2611,2618,2632,2639,2646,2653,2667,2674,2681,2688,2702,2709,2716,2723,2737,2744,2751,2758,2772,2779,2786,2793,2807,2814,2821,2828,2842,2849,2856,2863,2877,2884,2891,2898,2912,2919,2926,2933,2947,2954,2961,2968,2982,2989,2996,3003,3017,3024,3031,3038,3052,3059,3066,3073,3087,3094,3101,3108,3122,3129,3136,3143,3157,3164,3171,3178,3192,3199\n"
     ]
    }
   ],
   "source": [
    "Num = []\n",
    "for i in range(2000, 3201):\n",
    "    if (i % 7 == 0) and (i % 5 != 0):\n",
    "        Num.append(str(i))\n",
    "print(','.join(Num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c95e4",
   "metadata": {},
   "source": [
    "**2. Write a program that accepts a sentence and calculate the number of upper case letters and lower case letters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084b6f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence: Hello All Good Morning!\n",
      "Number of uppercase letters: --> 4\n",
      "Number of lowercase letters: --> 15\n"
     ]
    }
   ],
   "source": [
    "def count_upper_lower(sentence):\n",
    "    upper_count = 0\n",
    "    lower_count = 0\n",
    "    for letter in sentence:\n",
    "        if letter.isupper():\n",
    "            upper_count += 1\n",
    "        elif letter.islower():\n",
    "            lower_count += 1\n",
    "    print(f\"Number of uppercase letters: --> {upper_count}\")\n",
    "    print(f\"Number of lowercase letters: --> {lower_count}\")\n",
    "\n",
    "count_upper_lower(input(\"Enter a sentence: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142c513",
   "metadata": {},
   "source": [
    "**3. You are given a train data set having 1000 columns and 1 million rows. The data set is based on a classification problem. Your manager has asked you to reduce the dimension of this data so that model computation time can be reduced. Your machine bus, memory constraints. What would you do? (You are free in make practical assumptions.)**\n",
    "\n",
    "**ANS :**    To reduce the dimensionality of a dataset. We can employ dimensionality reduction methods like Principal Component Analysis (PCA), and Singular Value Decomposition (SVD). To choose a subset of the most pertinent features, we can also think about feature selection strategies. And to work with huge datasets that do not fit into memory, we can utilize randomized PCA (RPCA) or incremental PCA (IPCA). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d52624",
   "metadata": {},
   "source": [
    "**4. You are given a data set on cancer detection. You've build a classification model and achieved an accuracy of 96%. Why shouldn't you be happy with your model performance? What can you do about it.**\n",
    "\n",
    "**Explain print probability, likelihood and marginal likelihood in contest of naiveBayes algorithm?**\n",
    "\n",
    "**ANS :**    1) In the case of cancer we interested in minority class which is patients who actually have cancer. In our case the ratio is only 4% and the majority class is 96%. If we have worked on enough data sets, we should deduce that cancer detection results in imbalanced data.In an imbalanced dataset,accuracy should not be used as a measure of performance. \n",
    "\n",
    "1. Prior probability: The probability of each class before any characteristics are observed is known as the prior probability in the Naive Bayes method.\n",
    "2. Likelihood: In the Naive Bayes method, the likelihood is the likelihood of detecting each feature given the class.\n",
    "3. Marginal likelihood: The probability of witnessing the evidence is known as the marginal likelihood in the Naive Bayes method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea1e72b",
   "metadata": {},
   "source": [
    "**5. You are working on a time series data set. You manager has asked you to build a high accuracy model. You start with the decision tree sigurithm, since you know it works fairly well on all kinds of data. Later, you tried a time series regression model and got higher accuracy than decision tree model. can this happen? Why?**\n",
    "\n",
    "**ANS :**    Yes, it is possible to get higher accuracy with a time series regression model than with a decision tree algorithm. Time series data is known to possess linearity, and a decision tree algorithm is known to work best to detect non-linear interactions. The reason why the decision tree failed to provide robust predictions is that it couldn’t map the linear relationship as well as a regression model did "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0ec5a",
   "metadata": {},
   "source": [
    "**6. You came to know that your model is suffering from low bias and high variance. Which algorithm should you use to tackle it? Why**\n",
    "\n",
    "**ANS:**    Low bias and high variance indicate that your model is overfitting the training set and is not performing well when applied to fresh data. It is advised to apply regularization techniques in these situations to lower the model's variance. Regularization strategies like L1 or L2 regularization can lessen the likelihood of overfitting and enhance the model's capacity for generalization. An additional strategy is to apply group techniques like boosting or bagging. While boosting can be used to minimize bias in high-bias algorithms like linear regression, bagging can be used to reduce variance in high-variance algorithms like decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0e482b",
   "metadata": {},
   "source": [
    "**7. You are given a data set. The data set contains many variables, same of which are highly correlated and you know about it. Your manager has asked you to rum PCA Would you remove correlated variables first? Why?**\n",
    "\n",
    "**ANS :**    it is not necessary to remove correlated variables before performing Principal Component Analysis (PCA). PCA is a technique that identifies the principal components that explain the most variation in the data and reduces redundant information by creating a set of entirely uncorrelated components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00139e",
   "metadata": {},
   "source": [
    "**8. After analyzing the model, your manager has informed that your repression model is suffering from multicollinearity flow would you chack if he's true? Without losing any Information, can you still build a better model**\n",
    "\n",
    "**ANS :**    To check multicollinearity, we can create a correlation matrix to identify and to built better model we can use penalized regression models like ridge or lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e93d79",
   "metadata": {},
   "source": [
    "**9. When in Ridge regression favorable over Lasso regression? While working on a data set, how do you select important variables? Explain your methods.**\n",
    "\n",
    "**ANS:**    Ridge regression is favorable over Lasso regression when all the features in the dataset are important and none of them can be removed. Ridge regression is also preferred when the number of features is greater than the number of observations. To select important variables from a dataset, you can use methods such as univariate feature selection, recursive feature elimination, and regularization methods such as L1 or L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e2fda57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4173048330.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Temp\\ipykernel_9608\\4173048330.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    **10.\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "**10. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd1c84",
   "metadata": {},
   "source": [
    "**10.Running a binary classification tree algorithm is the easy part. Do you know how does a tree splitting takes place Le how does the tree decide which variable to split at the root node and succeeding nodes?**\n",
    "\n",
    "**ANS :**    A classification trees makes decision based on Gini Index and Node Entropy.The tree algorithm find the best possible feature which can divide the data set into purest possible children nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba3d5f",
   "metadata": {},
   "source": [
    "**11. You've got a data set to work having p (no of variable) n (no. of observation) Why is OLS as had option to work with? Which techniques would be best tu use? Why?**\n",
    "\n",
    "**ANS :**    Ordinary Least Squares (OLS) is a popular option for linear regression because it provides unbiased estimates of the regression coefficients and their standard errors. Some techniques that can be used to improve the performance of OLS include regularization, feature selection, and cross-validation. The choice of technique depends on the specific characteristics of the dataset and the goals of the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b849144",
   "metadata": {},
   "source": [
    "**12.  Define a function which can print a dictionary where the keys are numbers between 1 and 20 (both included)\n",
    "and the values are square of keys.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0224a8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81, 10: 100, 11: 121, 12: 144, 13: 169, 14: 196, 15: 225, 16: 256, 17: 289, 18: 324, 19: 361, 20: 400}\n"
     ]
    }
   ],
   "source": [
    "def generate_squared_dictionary():\n",
    "    squared_dict = {i: i**2 for i in range(1, 21)}\n",
    "    return squared_dict\n",
    "result_dict = generate_squared_dictionary()\n",
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaff58b",
   "metadata": {},
   "source": [
    "**13.  With a given tuple (1,2,3,4,5,6,7,8,9,10), write a program to print the first half values in one line and the last half values in one line.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c063db03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Half: (1, 2, 3, 4, 5)\n",
      "Second Half: (6, 7, 8, 9, 10)\n"
     ]
    }
   ],
   "source": [
    "my_tuple = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "print(\"First Half:\", my_tuple[:5])\n",
    "print(\"Second Half:\", my_tuple[5:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f603395",
   "metadata": {},
   "source": [
    "**14. Please write a programs to randomly generate a list with 5 even numbers between 100 and 200 inclusive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for i in range (10):\n",
    "    random_number = random.randint(100, 200)\n",
    "    if random_number%2==0:\n",
    "        print(random_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b19750",
   "metadata": {},
   "source": [
    "**15. Define a class Person and its own child lasser Male and Female. All classes have a method \"getGender\" which can print \"Male\" for Male class and \"Female\" for female class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ec45a15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male\n",
      "Female\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def getGender(self):\n",
    "        pass\n",
    "\n",
    "class Male(Person):\n",
    "    def getGender(self):\n",
    "        print(\"Male\")\n",
    "\n",
    "class Female(Person):\n",
    "    def getGender(self):\n",
    "        print(\"Female\")\n",
    "        \n",
    "            # OR\n",
    "        \n",
    "male = Male()\n",
    "male.getGender()\n",
    "\n",
    "female = Female()\n",
    "female.getGender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57fa08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
